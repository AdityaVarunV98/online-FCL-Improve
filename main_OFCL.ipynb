{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VARUN\\OneDrive\\Documents\\Semester_7\\RepresentationLearning\\online-FCL-Improve\\ofcl\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from configuration import config_jup\n",
    "from utils.data_loader import get_loader_all_clients\n",
    "from utils.train_utils import get_logger, initialize_clients, FedAvg, weightedFedAvg, test_global_model, compute_avg_acc_for, save_results\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--framework FRAMEWORK]\n",
      "                             [--dir_data DIR_DATA] [--dir_output DIR_OUTPUT]\n",
      "                             [--dataset_name DATASET_NAME]\n",
      "                             [--model_name MODEL_NAME]\n",
      "                             [--batch_size BATCH_SIZE] [--lr LR]\n",
      "                             [--optimizer OPTIMIZER] [--temp TEMP]\n",
      "                             [--sup_type SUP_TYPE]\n",
      "                             [--local_epochs LOCAL_EPOCHS]\n",
      "                             [--non_augment_epochs NON_AUGMENT_EPOCHS]\n",
      "                             [--n_runs N_RUNS] [--n_tasks N_TASKS]\n",
      "                             [--with_memory WITH_MEMORY]\n",
      "                             [--memory_size MEMORY_SIZE]\n",
      "                             [--update_strategy UPDATE_STRATEGY]\n",
      "                             [--sampling_strategy SAMPLING_STRATEGY]\n",
      "                             [--balanced_update BALANCED_UPDATE]\n",
      "                             [--uncertainty_score UNCERTAINTY_SCORE]\n",
      "                             [--subsample_size SUBSAMPLE_SIZE]\n",
      "                             [--balanced_step BALANCED_STEP]\n",
      "                             [--n_clients N_CLIENTS] [--overlap OVERLAP]\n",
      "                             [--burnin BURNIN] [--jump JUMP]\n",
      "                             [--fl_update FL_UPDATE] [--eval_gap EVAL_GAP]\n",
      "                             [--mu MU]\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=c:\\Users\\VARUN\\AppData\\Roaming\\jupyter\\runtime\\kernel-v3b4651491a42f35296879de7ad0ead5fa52685c3f.json could match --framework, --fl_update\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VARUN\\OneDrive\\Documents\\Semester_7\\RepresentationLearning\\online-FCL-Improve\\ofcl\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "args = config_jup.base_parser() # load the default arguments\n",
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "    args.device = f'cuda:0'\n",
    "else:\n",
    "    args.device = 'cpu' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(framework='FCL', dir_data='./data/', dir_output='./output/', dataset_name='cifar10', model_name='resnet', batch_size=10, lr=0.1, optimizer='sgd', local_epochs=3, n_runs=1, n_tasks=5, with_memory=1, memory_size=200, update_strategy='balanced', sampling_strategy='random', balanced_update='uncertainty', uncertainty_score='bregman', subsample_size=50, balanced_step='bottomk', n_clients=5, overlap='overlap', burnin=30, jump=5, fl_update='w_favg', mu=0.01, cuda=True, device='cuda:0', input_size=(3, 32, 32), n_classes=10, n_classes_per_task=2, dir_results='./output//FCL/cifar10/w_favg/overlap/5clients/5tasks/30/5/resnet/sgd/01/200/10/3/random/balanced_uncertainty/bregman/bottomk/')\n"
     ]
    }
   ],
   "source": [
    "# change the default arguments if needed (see example below)\n",
    "args.dataset_name = 'cifar10'\n",
    "args.memory_size = 200\n",
    "logger = get_logger(args)\n",
    "args.n_runs = 1\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data//data_splits/FCL/cifar10/overlap/5clients/5tasks/run0/cifar10_split.pkl\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Namespace' object has no attribute 'temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args.n_runs):\n\u001b[32m      2\u001b[39m     loader_clients, cls_assignment_list, global_test_loader = get_loader_all_clients(args, run)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     clients = \u001b[43minitialize_clients\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_clients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_assignment_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     start_time = datetime.now()\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m client \u001b[38;5;129;01min\u001b[39;00m clients:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VARUN\\OneDrive\\Documents\\Semester_7\\RepresentationLearning\\online-FCL-Improve\\utils\\train_utils.py:137\u001b[39m, in \u001b[36minitialize_clients\u001b[39m\u001b[34m(args, loader_clients, cls_assignment_list, run)\u001b[39m\n\u001b[32m    134\u001b[39m torch.backends.cudnn.deterministic = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    135\u001b[39m torch.backends.cudnn.benchmark = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m model, optimizer, criterion = \u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m memory_client = Memory(args)\n\u001b[32m    139\u001b[39m client = Client(args, loader_client, model, optimizer, criterion, memory_client, client_id, cls_assignment_client)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\VARUN\\OneDrive\\Documents\\Semester_7\\RepresentationLearning\\online-FCL-Improve\\utils\\train_utils.py:117\u001b[39m, in \u001b[36minitialize_model\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msupcon_loss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SupConLoss\n\u001b[32m    116\u001b[39m criterion_ce = torch.nn.CrossEntropyLoss()\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m criterion_supcon = SupConLoss(temperature=\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtemp\u001b[49m, contrast_mode=args.sup_type)\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# print(\"Supcon loss temperature: \", args.temp)\u001b[39;00m\n\u001b[32m    120\u001b[39m criteria = {\u001b[33m'\u001b[39m\u001b[33mce\u001b[39m\u001b[33m'\u001b[39m: criterion_ce, \u001b[33m'\u001b[39m\u001b[33msupcon\u001b[39m\u001b[33m'\u001b[39m: criterion_supcon}\n",
      "\u001b[31mAttributeError\u001b[39m: 'Namespace' object has no attribute 'temp'"
     ]
    }
   ],
   "source": [
    "for run in range(args.n_runs):\n",
    "    loader_clients, cls_assignment_list, global_test_loader = get_loader_all_clients(args, run)\n",
    "    clients = initialize_clients(args, loader_clients, cls_assignment_list, run)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    for client in clients:\n",
    "        print(client.model)\n",
    "    \n",
    "    # while not all([client.train_completed for client in clients]):\n",
    "    #     for client in clients:\n",
    "    #         if not client.train_completed:\n",
    "    #             samples, labels = client.get_next_batch()\n",
    "    #             if samples is not None:\n",
    "    #                 if args.with_memory:\n",
    "    #                     if client.task_id == 0:\n",
    "    #                         client.train_with_update(samples, labels)\n",
    "    #                     else:\n",
    "    #                         client.train_with_memory(samples, labels)\n",
    "    #                 else:\n",
    "    #                     client.train(samples, labels)\n",
    "    #             else:\n",
    "    #                 print(f'Run {run} - Client {client.client_id} - Task {client.task_id} completed - {client.get_current_task()}')\n",
    "    #                 # compute loss train\n",
    "    #                 logger = client.compute_loss(logger, run)\n",
    "    #                 print(f'Run {run} - Client {client.client_id} - Test time - Task {client.task_id}')\n",
    "    #                 logger = client.test(logger, run)\n",
    "    #                 logger = client.validation(logger, run)\n",
    "    #                 logger = client.forgetting(logger, run)\n",
    "\n",
    "    #                 if client.task_id + 1 >= args.n_tasks:\n",
    "    #                     client.train_completed = True\n",
    "    #                     print(f'Run {run} - Client {client.client_id} - Train completed')\n",
    "    #                     logger = client.balanced_accuracy(logger, run)\n",
    "    #                 else:\n",
    "    #                     client.task_id += 1\n",
    "\n",
    "    #     # COMMUNICATION ROUND PART\n",
    "    #     selected_clients = [client.client_id for client in clients if (client.num_batches >= args.burnin and client.num_batches % args.jump == 0 and client.train_completed == False)]\n",
    "    #     if len(selected_clients) > 1:\n",
    "    #         # communication round when all clients process a mini-batch\n",
    "    #         if args.fl_update.startswith('w_'):\n",
    "    #             global_model = weightedFedAvg(args, selected_clients, clients)\n",
    "    #         else:\n",
    "    #             global_model = FedAvg(args, selected_clients, clients)\n",
    "\n",
    "    #         global_parameters = global_model.state_dict()\n",
    "    #         # local models update with averaged global parameters\n",
    "    #         for client_id in selected_clients:\n",
    "    #             clients[client_id].save_last_local_model()\n",
    "    #             clients[client_id].update_parameters(global_parameters)\n",
    "    #             clients[client_id].save_last_global_model(global_model)\n",
    "\n",
    "    # end_time = datetime.now()\n",
    "    # print(f'Duration: {end_time - start_time}')\n",
    "    # # global model accuracy when all clients finish their training on all tasks (FedCIL ICLR2023)\n",
    "    # logger = test_global_model(args, global_test_loader, global_model, logger, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for client_id in range(args.n_clients):\n",
    "    print(f'Client {client_id}: {clients[client_id].task_list}')\n",
    "    print(np.mean(logger['test']['acc'][client_id], 0))\n",
    "    final_acc = np.mean(np.mean(logger[\"test\"][\"acc\"][client_id], 0)[args.n_tasks-1,:], 0)\n",
    "    final_for = np.mean(logger[\"test\"][\"forget\"][client_id])\n",
    "    final_bal_acc = np.mean(logger[\"test\"][\"bal_acc\"][client_id])\n",
    "    print(f'Final client accuracy: {final_acc:0.4f}')\n",
    "    print(f'Final client forgetting: {final_for:0.4f}')\n",
    "    print(f'Final client balanced accuracy: {final_bal_acc:0.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc, std_acc, mean_for, std_for = compute_avg_acc_for(args, logger)\n",
    "print(f'Final average accuracy: {mean_acc:0.4f} (+-) {std_acc:0.4f}')\n",
    "print(f'Final average forgetting: {mean_for:0.4f} (+-) {std_for:0.4f}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training results\n",
    "save_results(args, logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ofcl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
